{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiStory \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "### Setup\n",
    "\n",
    "Libraries and define constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import json\n",
    "import numpy as np\n",
    "import shutil\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to parquet\n",
    "\n",
    "First a converesion from csv is parquet makes everything faster. If the file is in place, you don't need to run it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_date = \"20200301\"\n",
    "lang = \"pl\"\n",
    "csv_path = f\"data/{lang}/{lang}wiki-{backup_date}-stub-meta-history1.csv\"\n",
    "csv_data = pd.read_csv(csv_path, quotechar ='|')\n",
    "# csv_data.to_parquet('data/input.parquet', engine='pyarrow')\n",
    "input_data = csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add days to parquet\n",
    "We need to add days to our parquet as that's how we will do clustering of words for later rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data = pd.read_parquet('data/input.parquet', engine='pyarrow')\n",
    "\n",
    "input_data['timestamp'] = pd.to_datetime(input_data['timestamp'])\n",
    "input_data['day'] = input_data.timestamp.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   page_id page_title  page_ns  revision_id                 timestamp  \\\n",
      "0        2        AWK        0            4 2001-10-09 11:11:04+00:00   \n",
      "1        2        AWK        0            5 2001-10-30 22:29:16+00:00   \n",
      "2        2        AWK        0        22391 2002-11-22 11:05:09+00:00   \n",
      "3        2        AWK        0        22395 2002-12-08 08:46:25+00:00   \n",
      "4        2        AWK        0        22396 2002-12-08 09:22:15+00:00   \n",
      "\n",
      "  contributor_id              contributor_name  bytes         day  \n",
      "0              0         imported>Paweł Jochym   3136  2001-10-09  \n",
      "1              0  chello062179000014.chello.pl   3098  2001-10-30  \n",
      "2              0             conversion script   3098  2002-11-22  \n",
      "3             56                         LiNiO   3055  2002-12-08  \n",
      "4              4                         Kpjas   3349  2002-12-08  \n"
     ]
    }
   ],
   "source": [
    "print(input_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input_data.to_parquet('data/with_date.parquet',engine='pyarrow')\n",
    "with_dates = input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cleanup and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with_dates = pd.read_parquet('data/with_date.parquet')\n",
    "# with_dates = with_dates[with_dates.page_title != 'Tartışma:Anasayfa']\n",
    "grouped_by_date_and_title = with_dates.groupby(['day','page_title']).count()\n",
    "grouped_by_date_and_title = grouped_by_date_and_title.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out unnecessary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_filter = {\n",
    "    \"tr\": [\n",
    "        \"Vikipedi\",\n",
    "        \"Kullanıcı:\",\n",
    "        \"wiki:\",\n",
    "        \"mesaj:\",\n",
    "        \"Anasayfa\",\n",
    "        \"Tartışma:\",\n",
    "        \"Kategori:\",\n",
    "        \"Şablon:\"\n",
    "          ],\n",
    "    \"en\":[\n",
    "        \"Wikipedia:\",\n",
    "        \"User:\",\n",
    "        \"wiki:\",\n",
    "        \"Talk:\",\n",
    "        \"Message:\",\n",
    "        \"Category:\",\n",
    "        \"Template:\",\n",
    "        \"Portal:\"\n",
    "    ],\n",
    "    \"de\": [\n",
    "        \"Diskussion:\",\n",
    "        \"Benutzer:\",\n",
    "    ],\n",
    "    \"ru\": [\n",
    "        \n",
    "    ],\n",
    "    \"es\":[\n",
    "        \n",
    "    ],\n",
    "    \"pt\":[\n",
    "        \n",
    "    ]\n",
    "}\n",
    "\n",
    "grouped_by_date_and_title[\"ignore\"] = False\n",
    "\n",
    "for word in words_to_filter[lang]:\n",
    "    grouped_by_date_and_title[\"ignore\"] = grouped_by_date_and_title[\"ignore\"] | grouped_by_date_and_title.page_title.str.contains(word)\n",
    "\n",
    "\n",
    "\n",
    "grouped_by_date_and_title = grouped_by_date_and_title.loc[grouped_by_date_and_title.ignore == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results as Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_by_date_and_title.to_parquet('data/grouped.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save daily JSON's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# grouped_by_date_and_title = pd.read_parquet('data/grouped.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "more_than_two = grouped_by_date_and_title[grouped_by_date_and_title['page_id']>1]\n",
    "more_than_two = more_than_two.reset_index()\n",
    "grouped_by_day = more_than_two.groupby('day')\n",
    "grouped_by_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleanup data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amcharts_data_path = \"./data/export\"\n",
    "shutil.rmtree(amcharts_data_path, ignore_errors=True)\n",
    "pathlib.Path(amcharts_data_path).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def write_head(arg):\n",
    "    index = arg[0]\n",
    "    group = arg[1]\n",
    "    filename = index\n",
    "    # tags = group.apply(lambda x: {x.page_id})\n",
    "    df = group.rename(columns={\"page_id\": \"revisions\", \"page_title\":\"title\"})\n",
    "    df = df[[\"title\", \"revisions\"]]\n",
    "    mean = np.mean(df[\"revisions\"])\n",
    "    df = df[df[\"revisions\"] >= mean]\n",
    "    df[:100].to_json(f'{amcharts_data_path}/{index}.json', orient='records')\n",
    "\n",
    "\n",
    "    \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "   executor.map(write_head, grouped_by_day)\n",
    "    \n",
    "dates = list(map(lambda x: x[0].strftime(\"%Y-%m-%d\"), grouped_by_day.day))\n",
    "    \n",
    "index_dict = {'dates': dates}\n",
    "with open(f'{amcharts_data_path}/index.json',\"w+\") as outfile:\n",
    "  json.dump(index_dict, outfile)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
