{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WikiStory \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "### Setup\n",
    "\n",
    "Libraries and define constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import json\n",
    "import numpy as np\n",
    "import shutil\n",
    "import pathlib\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to parquet\n",
    "\n",
    "First a converesion from csv is parquet makes everything faster. If the file is in place, you don't need to run it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_date = \"20200301\"\n",
    "lang = \"pt\"\n",
    "csv_path = f\"data/{lang}/{lang}wiki-{backup_date}-stub-meta-history1.csv\"\n",
    "csv_data = pd.read_csv(csv_path, quotechar ='|')\n",
    "# csv_data.to_parquet('data/input.parquet', engine='pyarrow')\n",
    "input_data = csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add days to parquet\n",
    "We need to add days to our parquet as that's how we will do clustering of words for later rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data = pd.read_parquet('data/input.parquet', engine='pyarrow')\n",
    "\n",
    "input_data['timestamp'] = pd.to_datetime(input_data['timestamp'])\n",
    "input_data['day'] = input_data.timestamp.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   page_id  page_title  page_ns  revision_id                 timestamp  \\\n",
      "0      220  Astronomia        0          170 2003-08-05 20:39:52+00:00   \n",
      "1      220  Astronomia        0          171 2003-08-27 21:42:16+00:00   \n",
      "2      220  Astronomia        0         1544 2003-08-27 21:42:31+00:00   \n",
      "3      220  Astronomia        0         1546 2003-12-20 14:24:26+00:00   \n",
      "4      220  Astronomia        0         1547 2003-12-20 18:37:27+00:00   \n",
      "\n",
      "  contributor_id contributor_name  bytes         day  \n",
      "0              0  200.251.205.xxx    401  2003-08-05  \n",
      "1              0  200.205.161.xxx      1  2003-08-27  \n",
      "2              0  200.205.161.xxx    401  2003-08-27  \n",
      "3   61.6.126.249        Anonymous   1165  2003-12-20  \n",
      "4              3        Rob Hooft   1462  2003-12-20  \n"
     ]
    }
   ],
   "source": [
    "print(input_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# input_data.to_parquet('data/with_date.parquet',engine='pyarrow')\n",
    "with_dates = input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cleanup and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with_dates = pd.read_parquet('data/with_date.parquet')\n",
    "# with_dates = with_dates[with_dates.page_title != 'Tartışma:Anasayfa']\n",
    "grouped_by_date_and_title = with_dates.groupby(['day','page_title']).count()\n",
    "grouped_by_date_and_title = grouped_by_date_and_title.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out unnecessary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-3944b8cba63d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0mgrouped_by_date_and_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords_to_filter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mgrouped_by_date_and_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrouped_by_date_and_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mgrouped_by_date_and_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'pt'"
     ]
    }
   ],
   "source": [
    "words_to_filter = {\n",
    "    \"tr\": [\n",
    "        \"Vikipedi\",\n",
    "        \"Kullanıcı:\",\n",
    "        \"wiki:\",\n",
    "        \"mesaj:\",\n",
    "        \"Anasayfa\",\n",
    "        \"Tartışma:\",\n",
    "        \"Kategori:\",\n",
    "        \"Şablon:\"\n",
    "          ],\n",
    "    \"en\":[\n",
    "        \"Wikipedia:\",\n",
    "        \"User:\",\n",
    "        \"wiki:\",\n",
    "        \"Talk:\",\n",
    "        \"Message:\",\n",
    "        \"Category:\",\n",
    "        \"Template:\",\n",
    "        \"Portal:\"\n",
    "    ],\n",
    "    \"de\": [\n",
    "        \"Diskussion:\",\n",
    "        \"Benutzer:\",\n",
    "    ],\n",
    "    \"ru\": [\n",
    "        \"Википедия:\",\n",
    "        \"Пользователь:\",\n",
    "        \"вики:\",\n",
    "        \"Обсуждение:\",\n",
    "        \"Сообщение:\",\n",
    "        \"Категория:\",\n",
    "        \"Шаблон:\",\n",
    "        \"Портал:\"\n",
    "    ],\n",
    "    \"es\":[\n",
    "        \n",
    "    ],\n",
    "    \"pl\":[\n",
    "        \n",
    "    ],\n",
    "    \"it\":[\n",
    "        \n",
    "    ],\n",
    "    \"sv\":[\n",
    "        \n",
    "    ]\n",
    "}\n",
    "\n",
    "grouped_by_date_and_title[\"ignore\"] = False\n",
    "\n",
    "for word in words_to_filter[lang]:\n",
    "    grouped_by_date_and_title[\"ignore\"] = grouped_by_date_and_title[\"ignore\"] | grouped_by_date_and_title.page_title.str.contains(word)\n",
    "\n",
    "\n",
    "\n",
    "grouped_by_date_and_title = grouped_by_date_and_title.loc[grouped_by_date_and_title.ignore == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Results as Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_by_date_and_title.to_parquet('data/grouped.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save daily JSON's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# grouped_by_date_and_title = pd.read_parquet('data/grouped.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "more_than_two = grouped_by_date_and_title[grouped_by_date_and_title['page_id']>1]\n",
    "more_than_two = more_than_two.reset_index()\n",
    "grouped_by_day = more_than_two.groupby('day')\n",
    "grouped_by_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleanup data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amcharts_data_path = f\"./data/export/{lang}\"\n",
    "shutil.rmtree(amcharts_data_path, ignore_errors=True)\n",
    "pathlib.Path(amcharts_data_path).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def write_head(arg):\n",
    "    index = arg[0]\n",
    "    group = arg[1]\n",
    "    filename = index\n",
    "    # tags = group.apply(lambda x: {x.page_id})\n",
    "    df = group.rename(columns={\"page_id\": \"revisions\", \"page_title\":\"title\"})\n",
    "    df = df[[\"title\", \"revisions\"]]\n",
    "    mean = np.mean(df[\"revisions\"])\n",
    "    df = df[df[\"revisions\"] >= mean]\n",
    "    df[:100].to_json(f'{amcharts_data_path}/{index}.json', orient='records')\n",
    "\n",
    "\n",
    "    \n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "   executor.map(write_head, grouped_by_day)\n",
    "    \n",
    "dates = list(map(lambda x: x[0].strftime(\"%Y-%m-%d\"), grouped_by_day.day))\n",
    "    \n",
    "index_dict = {'dates': dates}\n",
    "with open(f'{amcharts_data_path}/index.json',\"w+\") as outfile:\n",
    "  json.dump(index_dict, outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload results to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"aws s3 sync {amcharts_data_path} s3://wikihistory-data/{lang}\")\n",
    "subprocess.run(['aws',\"s3\",\"sync\",amcharts_data_path, f's3://wikihistory-data/{lang}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
